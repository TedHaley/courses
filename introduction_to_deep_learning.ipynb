{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "introduction_to_deep_learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOv5O7qQ4pFQY2x+aXqhUMh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TedHaley/courses/blob/master/introduction_to_deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6ZF8_k3wSG1",
        "colab_type": "text"
      },
      "source": [
        "Introduction to Neural Networks\n",
        "\n",
        "Overview:  \n",
        "Models such as linear regression can be used to make predictions. It makes predictions by generating weights for some parameters and then adding those parameters together, ex:\n",
        "\n",
        "\n",
        "y = m1X1 + m2X2 + b. \n",
        "\n",
        "salary = 10,000 * years_exp + 50,000\n",
        "\n",
        "\n",
        "Where m1 and m2 are the weights. We can also have linear models that have interacting variables, such as:\n",
        "\n",
        "\n",
        "y = (m1X1 * m2X2) + b. \n",
        "\n",
        "salary = (10,000 * years_exp * 1.1* age) + 50,000\n",
        "\n",
        "\n",
        "This is a very basic example of interactivity between variables. Neural networks are similar to this but take it to the next level as they model many iteractions between many inputs, and then use those interactions as inputs for other interactions.\n",
        "\n",
        "![alt text](https://upload.wikimedia.org/wikipedia/commons/thumb/4/46/Colored_neural_network.svg/280px-Colored_neural_network.svg.png)\n",
        "\n",
        "As nodes increase, so does the ability to capture interactions.\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1fdjoM2tBhsQektdjG1882m5TV9FD9rkg)\n",
        "\n",
        "Forward Propogation:  \n",
        "Forward propogation is when we place weights on the lines between nodes. The output node is equal to the sum of the input nodes times the line weights. This operation is dot product.\n",
        "\n",
        "Example:\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1eJ5OLqSjIDluwHcomk2tYZbyGHVK_IWi)\n",
        "\n",
        "hidden layer node 0 = (2 * 1) + (3 * 1) = 5\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtHXN3zGmBqi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXNfK1iE6yPX",
        "colab_type": "code",
        "outputId": "eb8d4846-1aea-45b6-9ea8-ae9ee5d18a1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "input_data = np.array([2, 3])\n",
        "\n",
        "weights = {\n",
        "    'node_0': np.array([1, 1]),\n",
        "    'node_1': np.array([-1, 1]),\n",
        "    'output': np.array([2, -1]),\n",
        "}\n",
        "\n",
        "# [2, 3] * [1, 1] = (2 * 1) + (3 * 1) = 5 \n",
        "node_0_value = (input_data * weights['node_0']).sum()\n",
        "node_1_value = (input_data * weights['node_1']).sum()\n",
        "output_value = (np.array([node_0_value, node_1_value]) * weights['output']).sum()\n",
        "\n",
        "print('node 0:', node_0_value)\n",
        "print('node 1:', node_1_value)\n",
        "print('Output:', output_value)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "node 0: 5\n",
            "node 1: 1\n",
            "Output: 9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MguAi-WO9fmE",
        "colab_type": "text"
      },
      "source": [
        "Activation Function:  \n",
        "Activation functions are found within the hidden layers. Activation functions allow hidden layers to capture non-linearities. One popular activation function is ReLU (rectified linear activation), with is 0 below zero, and linear above zero for x. In the below example, we are going to use tanh as our activation function.\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1R_aqYRh66slQSt3YY0n1wWRTOtF8DCRa)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxRcbNhP_IYM",
        "colab_type": "code",
        "outputId": "ce277a58-64f4-40da-cf96-80c732d9c7c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "input_data = np.array([2, 3])\n",
        "\n",
        "weights = {\n",
        "    'node_0': np.array([1, 1]),\n",
        "    'node_1': np.array([-1, 1]),\n",
        "    'output': np.array([2, -1]),\n",
        "}\n",
        "\n",
        "node_0_input = (input_data * weights['node_0']).sum()\n",
        "node_0_output = np.tanh(node_0_input)\n",
        "\n",
        "node_1_input = (input_data * weights['node_1']).sum()\n",
        "node_1_output = np.tanh(node_1_input)\n",
        "\n",
        "output = (np.array([node_1_input, node_1_output]) * weights['output']).sum()\n",
        "\n",
        "print('node 0:', node_0_output)\n",
        "print('node 1:', node_1_output)\n",
        "print('Output:', output)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "node 0: 0.9999092042625951\n",
            "node 1: 0.7615941559557649\n",
            "Output: 1.2384058440442351\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GkkQSydRasl",
        "colab_type": "code",
        "outputId": "a1aa602e-5064-4512-f4e4-2a819648ffea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Using ReLU function\n",
        "\n",
        "def relu(input):\n",
        "    '''0 below 0, x above 0.'''\n",
        "    # Calculate the value for the output of the relu function: output\n",
        "    output = max(0, input)\n",
        "    \n",
        "    # Return the value just calculated\n",
        "    return(output)\n",
        "\n",
        "# Calculate node 0 value: node_0_output\n",
        "node_0_input = (input_data * weights['node_0']).sum()\n",
        "node_0_output = relu(node_0_input)\n",
        "\n",
        "# Calculate node 1 value: node_1_output\n",
        "node_1_input = (input_data * weights['node_1']).sum()\n",
        "node_1_output = relu(node_1_input)\n",
        "\n",
        "# Put node values into array: hidden_layer_outputs\n",
        "hidden_layer_outputs = np.array([node_0_output, node_1_output])\n",
        "\n",
        "# Calculate model output (do not apply relu)\n",
        "model_output = (hidden_layer_outputs * weights['output']).sum()\n",
        "\n",
        "# Print model output\n",
        "print(model_output)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkkiP_6VTWfK",
        "colab_type": "text"
      },
      "source": [
        "Deep Networks  \n",
        " - Deep networks internally build representations of patterns in the data\n",
        " - Partially replace the need for feature engineering\n",
        " - Subsequrnt layers build increasingly sophisticated representations of raw data\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1QMVRnZHgG1FPYHgJ_c5_X1nj3Lws3ffP)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voo_GJJ9WWll",
        "colab_type": "code",
        "outputId": "c78b97e2-9dc9-459e-a3e6-43c1b2ae5765",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Multi-layer networks\n",
        "def predict_with_network(input_data, weights):\n",
        "    # Calculate node 0 in the first hidden layer\n",
        "    node_0_0_input = (input_data * weights['node_0_0']).sum()\n",
        "    node_0_0_output = relu(node_0_0_input)\n",
        "\n",
        "    # Calculate node 1 in the first hidden layer\n",
        "    node_0_1_input = (input_data * weights['node_0_1']).sum()\n",
        "    node_0_1_output = relu(node_0_1_input)\n",
        "\n",
        "    # Put node values into array: hidden_0_outputs\n",
        "    hidden_0_outputs = np.array([node_0_0_output, node_0_1_output])\n",
        "    \n",
        "    # Calculate node 0 in the second hidden layer\n",
        "    node_1_0_input = (hidden_0_outputs * weights['node_1_0']).sum()\n",
        "    node_1_0_output = relu(node_1_0_input)\n",
        "\n",
        "    # Calculate node 1 in the second hidden layer\n",
        "    node_1_1_input = (hidden_0_outputs * weights['node_1_1']).sum()\n",
        "    node_1_1_output = relu(node_1_1_input)\n",
        "\n",
        "    # Put node values into array: hidden_1_outputs\n",
        "    hidden_1_outputs = np.array([node_1_0_output, node_1_1_output])\n",
        "\n",
        "    # Calculate model output: model_output\n",
        "    model_output = (hidden_1_outputs * weights['output']).sum()\n",
        "    \n",
        "    # Return model_output\n",
        "    return(model_output)\n",
        "\n",
        "weights = {\n",
        "    'node_0_0': np.array([2, 4]),\n",
        "    'node_0_1': np.array([ 4, -5]),\n",
        "    'node_1_0': np.array([-1,  2]),\n",
        "    'node_1_1': np.array([1, 2]),\n",
        "    'output': np.array([2, 7])\n",
        " }\n",
        "input_data = np.array([3, 5])\n",
        "output = predict_with_network(input_data, weights)\n",
        "print(output)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "182\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99GtL4umYbdb",
        "colab_type": "text"
      },
      "source": [
        "Training a Network:  \n",
        "Neural networks are trained using labelled data. The value of the weights for each line are changed to get the desired output.\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1d65zM3Re55BS62mzqssqJS9XJxlvFaLJ)\n",
        "\n",
        "We use back propogation to go back and re-weight the lines to get the desired output.\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=12gM57rbKz0VQ9jYzyyDuNprv0Vy7Bn-e)\n",
        "\n",
        "The challenge becomes when we are trying to make multiple accurate predictions with a static network. Each outcome is associated with its own error.\n",
        "\n",
        "Loss Function  \n",
        "The loss function is used to aggregate errors in many predictions to form a single number. This is a measure of a model's predictive performance.\n",
        "\n",
        "A common loss function is Mean Squared Error (MSE), where we square each error and take the average of the squared errors. We need to optimize the weights of the model to minimize the loss function.\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1eKpqtdRmYIyBfiaC9LSpGzRofsbODznL)\n",
        "\n",
        "\n",
        "Optimize the Loss Function  \n",
        "A simple method for optmizing this loss function is by using gradient descent. We take the derivative at the current point to find the slope of the line. We take a step in the opposite direction of the slope to go to a minima.\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1V-gP00xaaRqOSzc6TR7YSsVrbMPbAjhN)\n",
        "\n",
        "We need to make sure we don't step too quickly as we might miss the minima. This is why we use learn rate (often 0.01)\n",
        "step size = learning rate * slope\n",
        "\n",
        "Slope Caluclation Example:  \n",
        "Node 1 = 3\n",
        "weight = 2\n",
        "Node 2 = 6\n",
        "Actual target = 10\n",
        "\n",
        "slope = 2 * error * input = 2 * (6-10) * 3 = -24\n",
        "new weight = weight - lr(slope) = 2 - 0.01(-24) = 2.24\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDjCx4j5Ztfj",
        "colab_type": "code",
        "outputId": "00674ad1-4540-438b-fe8d-4f5e3d3f4078",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Coding how weight changes affect accuracy\n",
        "\n",
        "def predict_with_network(input_data, weights):\n",
        "    # Calculate node 0 in the first hidden layer\n",
        "    node_0_input = (input_data * weights['node_0']).sum()\n",
        "    node_0_output = relu(node_0_input)\n",
        "\n",
        "    # Calculate node 1 in the first hidden layer\n",
        "    node_1_input = (input_data * weights['node_1']).sum()\n",
        "    node_1_output = relu(node_1_input)\n",
        "\n",
        "    # Put node values into array: hidden_1_outputs\n",
        "    hidden_1_outputs = np.array([node_0_output, node_1_output])\n",
        "\n",
        "    # Calculate model output: model_output\n",
        "    model_output = (hidden_1_outputs * weights['output']).sum()\n",
        "    \n",
        "    # Return model_output\n",
        "    return(model_output)\n",
        "\n",
        "# The data point you will make a prediction for\n",
        "input_data = np.array([0, 3])\n",
        "\n",
        "# Sample weights\n",
        "weights_0 = {'node_0': [2, 1],\n",
        "             'node_1': [1, 2],\n",
        "             'output': [1, 1]\n",
        "            }\n",
        "\n",
        "# The actual target value, used to calculate the error\n",
        "target_actual = 3\n",
        "\n",
        "# Make prediction using original weights\n",
        "model_output_0 = predict_with_network(input_data, weights_0)\n",
        "\n",
        "# Calculate error: error_0\n",
        "error_0 = model_output_0 - target_actual\n",
        "\n",
        "# Create weights that cause the network to make perfect prediction (3): weights_1\n",
        "weights_1 = {'node_0': [2, 1],\n",
        "             'node_1': [1, 2],\n",
        "             'output': [1, 0]\n",
        "            }\n",
        "\n",
        "# Make prediction using new weights: model_output_1\n",
        "model_output_1 = predict_with_network(input_data, weights_1)\n",
        "\n",
        "# Calculate error: error_1\n",
        "error_1 = model_output_1 - target_actual\n",
        "\n",
        "# Print error_0 and error_1\n",
        "print(error_0)\n",
        "print(error_1)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mvh2GThmugh",
        "colab_type": "code",
        "outputId": "02cce887-e5a8-4163-bd3d-fd2ea7607455",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Scaling up to multiple data points\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "weights_0 = {'node_0': [2, 1],\n",
        "             'node_1': [1, 2],\n",
        "             'output': [1, 1]\n",
        "            }\n",
        "\n",
        "weights_1 = {'node_0': [2, 1],\n",
        "             'node_1': [1, 1.5],\n",
        "             'output': [1, 1.5]\n",
        "            }\n",
        "\n",
        "input_data = [np.array([0, 3]), np.array([1, 2]), np.array([-1, -2]), np.array([4, 0])]\n",
        "target_actuals = [1, 3, 5, 7]\n",
        "\n",
        "# Create model_output_0 \n",
        "model_output_0 = []\n",
        "# Create model_output_1\n",
        "model_output_1 = []\n",
        "\n",
        "# Loop over input_data\n",
        "for row in input_data:\n",
        "    # Append prediction to model_output_0\n",
        "    model_output_0.append(predict_with_network(row, weights_0))\n",
        "    \n",
        "    # Append prediction to model_output_1\n",
        "    model_output_1.append(predict_with_network(row, weights_1))\n",
        "\n",
        "# Calculate the mean squared error for model_output_0: mse_0\n",
        "mse_0 = mean_squared_error(model_output_0, target_actuals)\n",
        "\n",
        "# Calculate the mean squared error for model_output_1: mse_1\n",
        "mse_1 = mean_squared_error(model_output_1, target_actuals)\n",
        "\n",
        "# Print mse_0 and mse_1\n",
        "print(\"Mean squared error with weights_0: %f\" %mse_0)\n",
        "print(\"Mean squared error with weights_1: %f\" %mse_1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean squared error with weights_0: 37.500000\n",
            "Mean squared error with weights_1: 49.890625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhWlb4zsvu6j",
        "colab_type": "text"
      },
      "source": [
        "Calculate slope and update weights\n",
        "\n",
        "Target is 6\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1isFICLF_N4x1pvs1jh04eKECBSRptS1t)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLg6ZpZZoQCs",
        "colab_type": "code",
        "outputId": "8fa976ba-a0b1-4d59-b6ba-7f8179fbfe35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Gradient descent \n",
        "import numpy as np\n",
        "\n",
        "weights = np.array([1, 2])\n",
        "input_data = np.array([3, 4])\n",
        "target = 6\n",
        "learning_rate = 0.01\n",
        "\n",
        "preds = (weights * input_data).sum()\n",
        "error = preds - target\n",
        "print(error)\n",
        "\n",
        "gradient = 2 * input_data * error\n",
        "weights_updated = weights - learning_rate * gradient\n",
        "\n",
        "preds_updated = (weights_updated * input_data).sum()\n",
        "error_updated = preds_updated - target\n",
        "print(error_updated)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "2.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLPVYDr-5IoD",
        "colab_type": "text"
      },
      "source": [
        "Creating a Keras model  \n",
        " - specify architechture\n",
        " - compile\n",
        " - fit\n",
        " - predict\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6dKKJ5T3zqC",
        "colab_type": "code",
        "outputId": "d7480cfa-ed51-49f3-8ffd-928bad26c078",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Model specification\n",
        "\n",
        "!pip install tensorflow==1.14.0\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "\n",
        "data = load_iris()\n",
        "predictors = pd.DataFrame(data = data.data, columns=data.feature_names)\n",
        "target = data['target']\n",
        "\n",
        "predictors.head()\n",
        "\n",
        "n_cols = predictors.shape[1]\n",
        "print(n_cols)\n",
        "\n",
        "# Dense layers connect every layer of the previous layer to the current layer\n",
        "# we are using 100 nodes per layer, but keras will set the number actually used\n",
        "# it is not uncommon to use many many more nodes in each layer\n",
        "model = Sequential() # Weights are only connected to the next deepest layer\n",
        "model.add(Dense(100, activation='relu', input_shape=(n_cols,))) # Number of input nodes and any number of rows\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(1)) # The output layer\n",
        "\n",
        "# Adam is a method of gradient descent that adjusts the learning rate dynamically\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(predictors, target)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
            "\u001b[K     |████████████████████████████████| 109.2MB 49kB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.18.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 52.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.9.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.34.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.3.3)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 51.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.28.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14.0) (46.1.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.2.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.2.0rc0\n",
            "    Uninstalling tensorflow-estimator-2.2.0rc0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0rc0\n",
            "  Found existing installation: tensorboard 2.2.0\n",
            "    Uninstalling tensorboard-2.2.0:\n",
            "      Successfully uninstalled tensorboard-2.2.0\n",
            "  Found existing installation: tensorflow 2.2.0rc2\n",
            "    Uninstalling tensorflow-2.2.0rc2:\n",
            "      Successfully uninstalled tensorflow-2.2.0rc2\n",
            "Successfully installed tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Epoch 1/1\n",
            "150/150 [==============================] - 0s 711us/step - loss: 2.6182\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f06cc436eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdZf-8ffmDSS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "df6c9ca8-5f02-4d81-b248-05a03dcd1a37"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>714.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>446.000000</td>\n",
              "      <td>0.383838</td>\n",
              "      <td>2.308642</td>\n",
              "      <td>29.699118</td>\n",
              "      <td>0.523008</td>\n",
              "      <td>0.381594</td>\n",
              "      <td>32.204208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>257.353842</td>\n",
              "      <td>0.486592</td>\n",
              "      <td>0.836071</td>\n",
              "      <td>14.526497</td>\n",
              "      <td>1.102743</td>\n",
              "      <td>0.806057</td>\n",
              "      <td>49.693429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>223.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>20.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.910400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>446.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.454200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>668.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>891.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>512.329200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       PassengerId    Survived      Pclass  ...       SibSp       Parch        Fare\n",
              "count   891.000000  891.000000  891.000000  ...  891.000000  891.000000  891.000000\n",
              "mean    446.000000    0.383838    2.308642  ...    0.523008    0.381594   32.204208\n",
              "std     257.353842    0.486592    0.836071  ...    1.102743    0.806057   49.693429\n",
              "min       1.000000    0.000000    1.000000  ...    0.000000    0.000000    0.000000\n",
              "25%     223.500000    0.000000    2.000000  ...    0.000000    0.000000    7.910400\n",
              "50%     446.000000    0.000000    3.000000  ...    0.000000    0.000000   14.454200\n",
              "75%     668.500000    1.000000    3.000000  ...    1.000000    0.000000   31.000000\n",
              "max     891.000000    1.000000    3.000000  ...    8.000000    6.000000  512.329200\n",
              "\n",
              "[8 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iy90wrwnpIag",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "9d511228-49f6-4a11-d984-7c6eb64c0a03"
      },
      "source": [
        "# Categorical predictions\n",
        "\n",
        "# Load Titanianic Data\n",
        "import pandas as pd\n",
        "\n",
        "train = pd.read_csv('/content/sample_data/train.csv')\n",
        "train.describe()\n",
        "\n",
        "# Import necessary modules\n",
        "import keras\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "# Convert the target to categorical: target\n",
        "target = to_categorical(train.Survived)\n",
        "print(target.shape)\n",
        "\n",
        "predictors = train[['Pclass',\t'Age',\t'SibSp',\t'Parch',\t'Fare']].to_numpy()\n",
        "n_cols = predictors.shape[1]\n",
        "\n",
        "# Set up the model\n",
        "model = Sequential()\n",
        "\n",
        "# Add the first layer\n",
        "model.add(Dense(32, activation='relu', input_shape=(n_cols,)))\n",
        "\n",
        "# Add the output layer\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(predictors, target, epochs=10, batch_size=32)\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(891, 2)\n",
            "Epoch 1/10\n",
            "891/891 [==============================] - 0s 114us/step - loss: nan - accuracy: 0.6229\n",
            "Epoch 2/10\n",
            "891/891 [==============================] - 0s 38us/step - loss: nan - accuracy: 0.6162\n",
            "Epoch 3/10\n",
            "891/891 [==============================] - 0s 35us/step - loss: nan - accuracy: 0.6162\n",
            "Epoch 4/10\n",
            "891/891 [==============================] - 0s 34us/step - loss: nan - accuracy: 0.6162\n",
            "Epoch 5/10\n",
            "891/891 [==============================] - 0s 34us/step - loss: nan - accuracy: 0.6162\n",
            "Epoch 6/10\n",
            "891/891 [==============================] - 0s 34us/step - loss: nan - accuracy: 0.6162\n",
            "Epoch 7/10\n",
            "891/891 [==============================] - 0s 33us/step - loss: nan - accuracy: 0.6162\n",
            "Epoch 8/10\n",
            "891/891 [==============================] - 0s 33us/step - loss: nan - accuracy: 0.6162\n",
            "Epoch 9/10\n",
            "891/891 [==============================] - 0s 35us/step - loss: nan - accuracy: 0.6162\n",
            "Epoch 10/10\n",
            "891/891 [==============================] - 0s 34us/step - loss: nan - accuracy: 0.6162\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f06864a9d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GINR8ORm9kQt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jUFwAKf2sr-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "37bf42ad-dfa9-4c49-a5f2-1deba8313fc1"
      },
      "source": [
        "test = pd.read_csv('/content/sample_data/test.csv')\n",
        "pred_data = test[['Pclass',\t'Age',\t'SibSp',\t'Parch',\t'Fare']].to_numpy()\n",
        "\n",
        "# Specify, compile, and fit the model\n",
        "model = Sequential()\n",
        "model.add(Dense(32, activation='relu', input_shape = (n_cols,)))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.compile(optimizer='sgd', \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "model.fit(predictors, target)\n",
        "\n",
        "# Calculate predictions: predictions\n",
        "predictions = model.predict(pred_data)\n",
        "print(predictions)\n",
        "\n",
        "# Calculate predicted probability of survival: predicted_prob_true\n",
        "predicted_prob_true = predictions[:,1]\n",
        "\n",
        "# print predicted_prob_true\n",
        "print(predicted_prob_true)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "891/891 [==============================] - 0s 138us/step - loss: nan - accuracy: 0.6117\n",
            "[[nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]\n",
            " [nan nan]]\n",
            "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKual5c39ln9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "955d19b2-4efe-4630-e505-91024e59729c"
      },
      "source": [
        "# Save the number of columns in predictors: n_cols\n",
        "n_cols = predictors.shape[1]\n",
        "input_shape = (n_cols,)\n",
        "\n",
        "# Specify the model\n",
        "model = Sequential()\n",
        "model.add(Dense(100, activation='relu', input_shape = input_shape))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "hist = model.fit(predictors, target, validation_split=0.3)\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 623 samples, validate on 268 samples\n",
            "Epoch 1/1\n",
            "623/623 [==============================] - 0s 350us/step - loss: nan - accuracy: 0.5891 - val_loss: nan - val_accuracy: 0.6418\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmD5B0aW-JP7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "29813220-6a83-44ff-db92-922bdf0718ff"
      },
      "source": [
        "# Import EarlyStopping\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Save the number of columns in predictors: n_cols\n",
        "n_cols = predictors.shape[1]\n",
        "input_shape = (n_cols,)\n",
        "\n",
        "# Specify the model\n",
        "model = Sequential()\n",
        "model.add(Dense(100, activation='relu', input_shape = input_shape))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define early_stopping_monitor\n",
        "early_stopping_monitor = EarlyStopping(patience=2)\n",
        "\n",
        "# Fit the model\n",
        "model.fit(predictors, target, validation_split=0.3, epochs=30, callbacks=[early_stopping_monitor])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 623 samples, validate on 268 samples\n",
            "Epoch 1/30\n",
            "623/623 [==============================] - 0s 360us/step - loss: nan - accuracy: 0.6003 - val_loss: nan - val_accuracy: 0.6418\n",
            "Epoch 2/30\n",
            "623/623 [==============================] - 0s 66us/step - loss: nan - accuracy: 0.6051 - val_loss: nan - val_accuracy: 0.6418\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f0685e0f080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCeYAzRB-uiX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "3902d823-dbc2-4193-f357-756469c1ad28"
      },
      "source": [
        "# Experimenting with wider networks\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define early_stopping_monitor\n",
        "early_stopping_monitor = EarlyStopping(patience=2)\n",
        "\n",
        "# Create the new model: model_2\n",
        "model_1 = Sequential()\n",
        "\n",
        "# Add the first and second layers\n",
        "model_1.add(Dense(10, activation='relu', input_shape = input_shape))\n",
        "\n",
        "model_1.add(Dense(10, activation='relu'))\n",
        "\n",
        "# Add the output layer\n",
        "model_1.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# Compile model_2\n",
        "model_1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Create the new model: model_2\n",
        "model_2 = Sequential()\n",
        "\n",
        "# Add the first and second layers\n",
        "model_2.add(Dense(100, activation='relu', input_shape = input_shape))\n",
        "\n",
        "model_2.add(Dense(100, activation='relu'))\n",
        "\n",
        "# Add the output layer\n",
        "model_2.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# Compile model_2\n",
        "model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fit model_1\n",
        "model_1_training = model_1.fit(predictors, target, epochs=15, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=False)\n",
        "\n",
        "# Fit model_2\n",
        "model_2_training = model_2.fit(predictors, target, epochs=15, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=False)\n",
        "\n",
        "# Create the plot\n",
        "plt.plot(model_1_training.history['val_loss'], 'r', model_2_training.history['val_loss'], 'b')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation score')\n",
        "plt.show()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEGCAYAAABLgMOSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAVHklEQVR4nO3df7BfdX3n8eeLRBGXFRIIiAQaFNQJrYq9hWG3nVJ+0xbDUHaFbccM2mW2yrpbqyMOrSDijLC1dl1ZbURtpLWgWGq6/mBDEPdHGeEG0Ao2JgIOIGj4IWu0gsH3/vE9kS+Xb26+Ofd+f3mfj5kz95zP+dzv9/0hM7zuOZ/zI1WFJEm7a49RFyBJmkwGiCSpFQNEktSKASJJasUAkSS1snjUBQzT/vvvXytWrBh1GZI0UTZu3PhwVS2b2b6gAmTFihVMT0+PugxJmihJvt2r3VNYkqRWDBBJUisGiCSpFQNEktSKASJJasUAkSS1YoBIkloxQCRJrRggkqRWDBBJUisGiCSpFQNEktSKASJJasUAkSS1YoBIkloxQCRJrRggkqRWDBBJUisGiCSpFQNEktSKASJJasUAkSS1YoBIkloxQCRJrRggkqRWRhogSU5NsinJliQX9Ni/Z5Jrmv1fSbJixv5Dk2xL8tZh1SxJ6hhZgCRZBFwBnAasBM5JsnJGtzcAj1XV4cD7gctm7P8z4AuDrlWS9GyjPAI5GthSVXdX1ZPA1cCqGX1WAWub9WuBE5IEIMkZwD3AnUOqV5LUZZQBcjBwX9f2/U1bzz5VtR14HNgvyd7A24F37epLkpyXZDrJ9NatW+elcEnS5E6iXwy8v6q27apjVa2pqqmqmlq2bNngK5OkBWLxCL/7AeCQru3lTVuvPvcnWQzsAzwCHAOcleRyYF/gp0l+XFUfHHzZkiQYbYDcChyR5DA6QXE28O9m9FkHrAZuBs4CbqyqAn5tR4ckFwPbDA9JGq6RBUhVbU9yPnA9sAj4WFXdmeQSYLqq1gEfBa5KsgV4lE7ISJLGQDp/0C8MU1NTNT09PeoyJGmiJNlYVVMz2yd1El2SNGIGiCSpFQNEktSKASJJasUAkSS1YoBIkloxQCRJrRggkqRWDBBJUisGiCSpFQNEktSKASJJasUAkSS1YoBIkloxQCRJrRggkqRWDBBJUisGiCSpFQNEktSKASJJasUAkSS1YoBIkloxQCRJrRggkqRWDBBJUisGiCSpFQNEktSKASJJasUAkSS1YoBIkloZaYAkOTXJpiRbklzQY/+eSa5p9n8lyYqm/aQkG5P8Y/Pz+GHXLkkL3cgCJMki4ArgNGAlcE6SlTO6vQF4rKoOB94PXNa0PwycXlW/BKwGrhpO1ZKkHUZ5BHI0sKWq7q6qJ4GrgVUz+qwC1jbr1wInJElV3V5V32na7wT2SrLnUKqWJAGjDZCDgfu6tu9v2nr2qartwOPAfjP6/A5wW1U9MaA6JUk9LB51AXOR5Eg6p7VOnqXPecB5AIceeuiQKpOkn3+jPAJ5ADika3t509azT5LFwD7AI832cuA64HVV9a2dfUlVramqqaqaWrZs2TyWL0kL2y4DJMlLk2xI8vVm+xVJ/ngevvtW4IgkhyV5LnA2sG5Gn3V0JskBzgJurKpKsi/wOeCCqvq/81CLJGk39XME8hHgHcBPAKrqa3T+Zz8nzZzG+cD1wDeAT1XVnUkuSfKapttHgf2SbAHeAuy41Pd84HDgnUnuaJYD5lqTJKl//cyBPL+qbknS3bZ9Pr68qj4PfH5G2zu71n8M/Jsev3cpcOl81CBJaqefI5CHk7wEKIAkZwEPDrQqSdLY6+cI5E3AGuDlSR4A7gF+d6BVSZLG3qwB0twt/saqOjHJvwD2qKofDKc0SdI4mzVAquqpJL/arP9wOCVJkiZBP6ewbk+yDvg08LMQqaq/HVhVkqSx10+API/OzXvdT7wtwACRpAVslwFSVecOoxBJ0mTp50705UmuS/K9ZvlM8xgRSdIC1s99IB+n80iRFzXL3zdtkqQFrJ8AWVZVH6+q7c3yl4BPJZSkBa6fAHkkye8lWdQsv0fzRFxJ0sLVT4C8Hvi3wEN0HmFyFuDEuiQtcP1chfVt4DW76idJWlj6uQprbfP+jR3bS5J8bLBlSZLGXT+nsF5RVd/fsVFVjwFHDa4kSdIk6CdA9kiyZMdGkqVM+LvUJUlz108QvA+4OcmngdCZRH/PQKuSJI29fibRP5FkmqefhXVmVd012LIkSeNulwHSvI3wW1V1V5LjgBOTfKd7XkSStPD0MwfyGeCpJIcDfwEcAnxyoFVJksZePwHy06raDpwJfLCq3gYcNNiyJEnjrp8A+UmSc4DXAf+jaXvO4EqSJE2CfgLkXOBY4D1VdU+Sw4CrBluWJGnc9XMV1l3Am7u27wEuG2RRkqTx188RiCRJz2KASJJaMUAkSa30cyPhS4G3Ab/Q3b+qjt/pL0mSfu718yysTwMfBj4CPDXYciRJk6KfANleVR8aeCWSpInSzxzI3yd5Y5KDkizdsQy8MknSWOsnQFbTmQP5B2Bjs0zPx5cnOTXJpiRbklzQY/+eSa5p9n8lyYqufe9o2jclOWU+6pEk9a+fGwkPG8QXJ1kEXAGcBNwP3Jpk3YxHxb8BeKyqDk9yNp0bGF+bZCVwNnAk8CLghiQvrSrnaCRpSPp5J/pzkrw5ybXNcn6S+XgW1tHAlqq6u6qeBK4GVs3oswpY26xfC5yQJE371VX1RHNn/Jbm8yRJQ9LPKawPAb8M/Pdm+eWmba4OBu7r2r6/aevZp3ki8OPAfn3+LgBJzksynWR669at81C2JAn6uwrrV6rqlV3bNyb56qAKmm9VtQZYAzA1NVUjLkeSfm70cwTyVPNWQgCSvJj5uR/kATovp9phedPWs0+SxcA+wCN9/q4kaYD6CZC3AV9KclOSLwM3An80D999K3BEksOSPJfOpPi6GX3W0bkKDOAs4Maqqqb97OYqrcOAI4Bb5qEmSVKf+rkKa0OSI4CXNU2bquqJuX5xVW1Pcj5wPbAI+FhV3ZnkEmC6qtYBHwWuSrIFeJROyND0+xRwF7AdeJNXYEnScKXzB32PHcnxVXVjkjN77a+qvx1oZQMwNTVV09PzcguLJC0YSTZW1dTM9tmOQH6dzumq03vsK2DiAkSSNH92GiBVdVGzeklzr8XPNPMOkqQFrJ9J9M/0aLt2vguRJE2WnR6BJHk5nUeF7DNjHuQFwPMGXZgkabzNNgfyMuC3gX155jzID4B/P8iiJEnjb7Y5kM8Cn01ybFXdPMSaJEkToJ9Hmdye5E10Tmf97NRVVb1+YFVJksZeP5PoVwEvBE4BvkznsSE/GGRRkqTx10+AHF5VfwL8sKrWAr8FHDPYsiRJ466fAPlJ8/P7SX6RzgMNDxhcSZKkSdDPHMiaJEuAP6HzEMO9gXcOtCpJ0tjr52GKVzarXwZePNhyJEmTYrYbCd8y2y9W1Z/NfzmSpEkx2xHIv2x+vgz4FZ5+V8fp+O4NSVrwZruR8F0ASf4X8Oqq+kGzfTHwuaFUJ0kaW/1chXUg8GTX9pNNmyRpAevnKqxPALckua7ZPgP4y4FVJEmaCP1chfWeJF8Afq1pOreqbh9sWZKkcTfbVVgvqKr/l2QpcG+z7Ni3tKoeHXx5kqRxNdsRyCfpPM59I51X2O6QZtt7QiRpAZvtKqzfbn76+lpJ0rPMdgrr1bP9YlXdNv/lSJImxWynsN43y74Cjp/nWiRJE2S2U1i/McxCJEmTpZ/7QGge476SZ76R8BODKkqSNP52GSBJLgKOoxMgnwdOA/4PnRsMJUkLVD+PMjkLOAF4qKrOBV5J56VSkqQFrJ8A+eeq+imwPckLgO8Bhwy2LEnSuOtnDmQ6yb7AR+jcVLgNuHmgVUmSxt5s94FcAXyyqt7YNH04yReBF1TV14ZSnSRpbM12CuubwJ8muTfJ5UmOqqp75yM8kixNsj7J5ubnkp30W9302ZxkddP2/CSfS/JPSe5M8t651iNJ2n07DZCq+q9VdSzw68AjwMea/2lflOSlc/zeC4ANVXUEsKHZfobmIY4XAccARwMXdQXNn1bVy4GjgH+d5LQ51iNJ2k27nESvqm9X1WVVdRRwDp33gXxjjt+7CljbrK9tPnOmU4D1VfVoVT0GrAdOraofVdWXmtqeBG4Dls+xHknSbtplgCRZnOT0JH8NfAHYBJw5x+89sKoebNYfovcbDg8G7uvavr9p665tXzrvaN8wx3okSbtptkn0k+gccfwmcAtwNXBeVf2wnw9OcgPwwh67LuzeqKpKUj367erzFwN/A3ygqu6epd95wHkAhx566O5+jSRpJ2a7jPcddN4J8kfNKaTdUlUn7mxfku8mOaiqHkxyEJ17S2Z6gM4d8DssB27q2l4DbK6qP99FHWuavkxNTe12UEmSepttEv34qrqyTXj0YR2wullfDXy2R5/rgZOTLGkmz09u2khyKZ274f/zAGqTJPWhnzvRB+G9wElJNgMnNtskmUpyJUDzytx3A7c2yyVV9WiS5XROg60EbktyR5LfH8UgJGkhS9XCOaszNTVV09PToy5DkiZKko1VNTWzfVRHIJKkCWeASJJaMUAkSa0YIJKkVgwQSVIrBogkqRUDRJLUigEiSWrFAJEktWKASJJaMUAkSa0YIJKkVgwQSVIrBogkqRUDRJLUigEiSWrFAJEktWKASJJaMUAkSa0YIJKkVgwQSVIrBogkqRUDRJLUigEiSWrFAJEktWKASJJaMUAkSa0YIJKkVgwQSVIrBogkqRUDRJLUykgCJMnSJOuTbG5+LtlJv9VNn81JVvfYvy7J1wdfsSRpplEdgVwAbKiqI4ANzfYzJFkKXAQcAxwNXNQdNEnOBLYNp1xJ0kyjCpBVwNpmfS1wRo8+pwDrq+rRqnoMWA+cCpBkb+AtwKVDqFWS1MOoAuTAqnqwWX8IOLBHn4OB+7q272/aAN4NvA/40a6+KMl5SaaTTG/dunUOJUuSui0e1AcnuQF4YY9dF3ZvVFUlqd343FcBL6mqP0yyYlf9q2oNsAZgamqq7++RJM1uYAFSVSfubF+S7yY5qKoeTHIQ8L0e3R4AjuvaXg7cBBwLTCW5l079ByS5qaqOQ5I0NKM6hbUO2HFV1Wrgsz36XA+cnGRJM3l+MnB9VX2oql5UVSuAXwW+aXhI0vCNKkDeC5yUZDNwYrNNkqkkVwJU1aN05jpubZZLmjZJ0hhI1cKZFpiamqrp6elRlyFJEyXJxqqamtnuneiSpFYMEElSKwaIJKkVA0SS1IoBIklqxQCRJLVigEiSWjFAJEmtGCCSpFYMEElSKwaIJKkVA0SS1IoBIklqxQCRJLVigEiSWjFAJEmtGCCSpFYMEElSKwaIJKkVA0SS1IoBIklqxQCRJLVigEiSWjFAJEmtpKpGXcPQJNkKfHvUdeym/YGHR13EkDnmhcExT45fqKplMxsXVIBMoiTTVTU16jqGyTEvDI558nkKS5LUigEiSWrFABl/a0ZdwAg45oXBMU8450AkSa14BCJJasUAkSS1YoCMgSRLk6xPsrn5uWQn/VY3fTYnWd1j/7okXx98xXM3lzEneX6SzyX5pyR3JnnvcKvfPUlOTbIpyZYkF/TYv2eSa5r9X0myomvfO5r2TUlOGWbdc9F2zElOSrIxyT82P48fdu1tzOXfuNl/aJJtSd46rJrnRVW5jHgBLgcuaNYvAC7r0WcpcHfzc0mzvqRr/5nAJ4Gvj3o8gx4z8HzgN5o+zwX+N3DaqMe0k3EuAr4FvLip9avAyhl93gh8uFk/G7imWV/Z9N8TOKz5nEWjHtOAx3wU8KJm/ReBB0Y9nkGOt2v/tcCngbeOejy7s3gEMh5WAWub9bXAGT36nAKsr6pHq+oxYD1wKkCSvYG3AJcOodb50nrMVfWjqvoSQFU9CdwGLB9CzW0cDWypqrubWq+mM/Zu3f8trgVOSJKm/eqqeqKq7gG2NJ837lqPuapur6rvNO13Ansl2XMoVbc3l39jkpwB3ENnvBPFABkPB1bVg836Q8CBPfocDNzXtX1/0wbwbuB9wI8GVuH8m+uYAUiyL3A6sGEQRc6DXY6hu09VbQceB/br83fH0VzG3O13gNuq6okB1TlfWo+3+ePv7cC7hlDnvFs86gIWiiQ3AC/ssevC7o2qqiR9X1ud5FXAS6rqD2eeVx21QY256/MXA38DfKCq7m5XpcZRkiOBy4CTR13LgF0MvL+qtjUHJBPFABmSqjpxZ/uSfDfJQVX1YJKDgO/16PYAcFzX9nLgJuBYYCrJvXT+PQ9IclNVHceIDXDMO6wBNlfVn89DuYPyAHBI1/bypq1Xn/ubUNwHeKTP3x1HcxkzSZYD1wGvq6pvDb7cOZvLeI8BzkpyObAv8NMkP66qDw6+7Hkw6kkYlwL4LzxzQvnyHn2W0jlPuqRZ7gGWzuizgsmZRJ/TmOnM93wG2GPUY9nFOBfTmfw/jKcnWI+c0edNPHOC9VPN+pE8cxL9biZjEn0uY9636X/mqMcxjPHO6HMxEzaJPvICXAo65343AJuBG7r+JzkFXNnV7/V0JlK3AOf2+JxJCpDWY6bzF14B3wDuaJbfH/WYZhnrbwLfpHOlzoVN2yXAa5r159G5AmcLcAvw4q7fvbD5vU2M6ZVm8zlm4I+BH3b9u94BHDDq8Qzy37jrMyYuQHyUiSSpFa/CkiS1YoBIkloxQCRJrRggkqRWDBBJUisGiDRHSZ5KckfX8qynsc7hs1dMyhOWtfB4J7o0d/9cVa8adRHSsHkEIg1IknuTXN682+KWJIc37SuS3Jjka0k2JDm0aT8wyXVJvtos/6r5qEVJPtK8++R/Jtmr6f/mJHc1n3P1iIapBcwAkeZurxmnsF7bte/xqvol4IPAjmd2/TdgbVW9Avhr4ANN+weAL1fVK4FX8/TjvY8ArqiqI4Hv03lKLXQeAXNU8zn/YVCDk3bGO9GlOUqyrar27tF+L3B8Vd2d5DnAQ1W1X5KHgYOq6idN+4NVtX+SrcDy6np8efOE5fVVdUSz/XbgOVV1aZIvAtuAvwP+rqq2DXio0jN4BCINVu1kfXd0vw/jKZ6eu/wt4Ao6Ryu3Nk95lYbGAJEG67VdP29u1v+BzhNZAX6Xzit5ofNwyT8ASLIoyT47+9AkewCHVOfNjG+n83jwZx0FSYPkXyzS3O2V5I6u7S9W1Y5LeZck+Rqdo4hzmrb/CHw8yduArcC5Tft/AtYkeQOdI40/AB6kt0XAXzUhEzov1fr+vI1I6oNzINKANHMgU1X18KhrkQbBU1iSpFY8ApEkteIRiCSpFQNEktSKASJJasUAkSS1YoBIklr5/xegnqWE80AEAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAM7rDM6CZlc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "fa50c4c5-1ef1-4a13-add7-f129e77fc1a2"
      },
      "source": [
        "# The input shape to use in the first hidden layer\n",
        "input_shape = (n_cols,)\n",
        "\n",
        "# Add the first, second, and third hidden layers\n",
        "# Create the new model: model_2\n",
        "model_2 = Sequential()\n",
        "\n",
        "# Add the first and second layers\n",
        "model_2.add(Dense(50, activation='relu', input_shape = input_shape))\n",
        "\n",
        "model_2.add(Dense(50, activation='relu'))\n",
        "\n",
        "model_2.add(Dense(50, activation='relu'))\n",
        "\n",
        "# Add the output layer\n",
        "model_2.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# Compile model_2\n",
        "model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fit model 1\n",
        "model_1_training = model_1.fit(predictors, target, epochs=20, validation_split=0.4, callbacks=[early_stopping_monitor], verbose=False)\n",
        "\n",
        "# Fit model 2\n",
        "model_2_training = model_2.fit(predictors, target, epochs=20, validation_split=0.4, callbacks=[early_stopping_monitor], verbose=False)\n",
        "\n",
        "# Create the plot\n",
        "plt.plot(model_1_training.history['val_loss'], 'r', model_2_training.history['val_loss'], 'b')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation score')\n",
        "plt.show()\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsZzO92hE0JV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}